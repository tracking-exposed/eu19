

Today I want to talk about a project named ALEX, which is the acronym for Algorithm Exposed, and one of its first output: a tool for scientific analysis of the social network personalisation algorithm, that we call fbtrex, facebook.tracking.exposed. It works by collecting what Facebook sends to you, as your timeline. Because is personalised, it can be collected as evidence and used to understand the algorithm logic.


First, let me tell you how the idea started, and the road so far. The project begins almost two years ago, as a way to understand the algorithm used by FB to organise users’ timeline. My vision was to increase transparency behind personalisation algorithms so that we can start having more effective control of our online experience, and more awareness of the logic behind how information circulates. That’s why the name, Algorithm "Exposed" (ALEX).

The team and I did so by asking people to “donate their digital body” to the science. People who use Facebook can now download a browser extension and become part of the first community that helps research that works on the impact and the dynamics of Automated Decision Making in our life and society. Every FB access creates a different timeline, a window into the organisational ability of the algorithm. But once the user refreshes the page, that chunk of information is lost. We can capture and store that instant we collect forensically valid evidence that can be used for policy-making, sciences, and the education of people on algorithm influence into society.

The project has received attention during our first months. We presented at many international conferences and run many more local events apt at educating and testing the tool. After a first, small round of funding from Lush DigitalFund, 11.000 euro, we have now raised 150.000 euro from the European Research Council, who gave us the mandate to develop technologies that increase algorithm literacy. We are pretty happy about this because we don’t want to sell our data, we want to exist in the public interest, as a free software project. The GDPR was the right step toward granting people rights in the digital world, now we think it’s time to focus on which ideals, and which ethical considerations should drive our approach techno-political issues.

We believe this mission to be highly interdisciplinary in nature, and it is our primary intention to engage with artists, social scientist and people outside of the technical world to capture all the aspects of how algorithms have an impact in everyday life.

Think about a common thing that still today transmit information: newspapers. They all base their report on events, but they differ in style, focus, and approach. We are all familiar with how they report news differently. We learn how to recognise their diversity, and we decide where we want to stay, on a spectrum of options. What they do, is they craft and organise information, pretty much like FB would do. However, while we do have many newspapers around, and we are able to “change” how information is organised by reading another newspaper, we cannot do the same with the “newspaper FB”, the information within which we can only read it that way, the Facebook way. Thinking about FB as a media platform is not entirely accurate (it’s not in its DNA) but it is helpful to get the idea behind our primary concern that an algorithm is a form of social power; we can’t avoid their presence because of the amount of information available, but we need to understand the spectrum and exert our agenda, somehow. 
 
We know an alleged solution is to migrate to a better platform (every Facebook PR would say “nobody force you to stay on Facebook”) but the network effect ensures this is in fact not a viable option for many people on the network. Not only that: for one single expert who has tools to do fact-checking, getting accurate information, experiment different networks, there are hundred for which Facebook is synonymous with the internet. As we have seen the last couple of years at least, the opaqueness of FB algorithms have been exploited in many ways, and perhaps is the manipulation of political events that is the most frightening. Sure, political manipulation is nothing new, but political manipulation that exploits users political inclinations is different; because it is personal and automated; and the only way to realise it is to share your phone with someone else, which is not really viable. This is the technical challenge we face: to enable citizen having a partial copy of what Facebook selects for them. It is a fundamental step to engage with peers, verify how differently you perceive a complex issue, and understand how your personalised newspaper is different from one of your friends, colleagues, partners.

FbTrex offers a new potential reality of how users and algorithms can co-exist, by allowing users agency and ownership over the algorithm, and letting users experiment with all of the possible alternatives for social interactions, information, and news that an algorithm can display. Our goal is to develop the idea of algorithmic diversity into a series of accessible interfaces and design to help journalists, researchers, and activist to look into the black box of facebook. We want to help users access non algorithmically curated Facebook data, and to experiment with different algorithms, to make their best Facebook fact newspaper. 

Maybe, parallel to the implication that the General Public License had on the free software world, we can think of an algorithm ’s public license with a similar clause. Let me put it this way: Think of an algorithm as a commodity you can plug and change, according to your own preference and design. Imagine you can change it, remix, share it with someone else. An algorithm implements a set of values which defines priorities and urgencies. You, or people you decide to trust, should have the ability to control these value, not the opaque logic of a corporation which promises to make the world more connected. 

The support of the European Research Council is and will be used in this direction: to support research on Automated Decision Making in our life and society, and hopefully better policies. I believe that the best model, and the model that worked for us, is focusing on the relations with external partners and talking with the business and academic worlds made us what we are today.

The good news is that we have done a good job so far, and we’ve just started (that’s why the funding from the EU I suppose). In between 2016 and 2018, we track elections in Netherland, France, and Italy, and developed and honed fbtrex plugin to allow users, journalists, and researcher to monitor the influence of the algorithm on elections. But elections are just a launch pad of attention: the algorithms have everyday controls, in every context, that’s why we don’t want to be a research team, but rather, a technology used by people to talk among them. The make criticism on algorithm something more usable. We don’t have yet a community, but using trampolines and targeted communication such as eu19.tracking. Exposed we can engage.

Despite our mission does not revolve around academic research, the academic community engaged in our work right from the start, and so far the use of our tool by the academic community resulted in three peer-reviewed publications and two reports backed by NGO, like WebFoundation and Tactical Tech. The support of the European Research Council is and will be used to support research on Automated Decision Making in our life and society, and hopefully better policies. I believe that the best model, and the model that worked for us, is focusing on the relations with external partners and talking with the business and academic worlds made us what we are today.

But first and foremost, we now have two goals.

First, we want to make FB more similar to the good old newspapers, concerning accountability. We are currently developing new technologies to release unfiltered, raw FB data. First thing RSS (hear that, Aaron?). This is just a simple experiment to give people, journalists, extra but decisive help to be able to search into the unfiltered flow of FB.

Our second goal is then to develop the idea of algorithmic diversity into a series of accessible interfaces and design, to do two things:

First, allow users to experiment with different algorithms, to make their best Facebook fact newspaper. FbTrex offers a new potential reality of how users and algorithms can co-exist, by allowing users agency and ownership over the algorithm, and letting users experiment with all of the possible alternatives for social interactions, information, and news that an algorithm can display.

Second, allow users, journalists, and researcher to monitor the influence of the algorithm on elections. In between 2016 and 2018, we track elections in Netherland, France, Argentina and Italy, and calculate what we call “information diet”, that is the degree of exposure of a specific chunk of information based on the user’s tracked behaviour.

As more of the academic and business world is joining the party (we hope to do great things with the University of Amsterdam, and we have great business advisors) we are launching our next call for action on the European Elections 2019. This is a pan-European effort aimed at one goal: observe narratives around the EU electoral campaigns to support and foster a deeper understanding of data exploitation models and algorithms by social media platforms such as Facebook. We wish to develop and increase awareness of online political advertisements and targeting and give reporters and activist a way to monitor political campaigns and the use of the network in targeting people and opinions and sharing advertisements.

So, having the European elections in mind, if you are on FB, please donate your digital body to science! And if you are a developer looking to work on an exciting project, feel free to approach me at the end of the session. Thanks for your attention.
